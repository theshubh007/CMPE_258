{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ge0NPUv_CWtK"
      },
      "source": [
        "# LangGraph Agent Patterns - Building Effective Agents\n",
        "\n",
        "This colab demonstrates common agent patterns from \"Building effective agents\" using the LangGraph framework. We'll implement several key patterns:\n",
        "1. Memory-based Agent\n",
        "2. Tool-using Agent  \n",
        "3. Multi-agent Collaboration\n",
        "4. Planning Agent\n",
        "\n",
        "We'll use LangGraph's workflow system to build these patterns and integrate with LangSmith for tracing and debugging. For this demo, we'll use the free Gemini API from Google."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required dependencies\n",
        "!pip install -q langgraph langsmith langchain langchain-google-genai langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hpr64ACoj6A2",
        "outputId": "57f94ed6-44fd-42f2-a6c8-c572b2996ed5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.2/151.2 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.6/47.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BtTW4eGICVZ6"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import json\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "from langchain_community.tools import WikipediaQueryRun\n",
        "from langchain_community.utilities import WikipediaAPIWrapper\n",
        "\n",
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "# Initialize LLM with Gemini\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    temperature=0.7,\n",
        "    google_api_key=GOOGLE_API_KEY\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkIoSnwmCe-c"
      },
      "source": [
        "## 1. Memory-based Agent Implementation\n",
        "\n",
        "This agent maintains conversation history and context across interactions. It uses LangGraph's checkpointing mechanism to store state between calls, enabling the agent to remember previous interactions and provide contextual responses.\n",
        "\n",
        "Key features:\n",
        "- Persistent memory across sessions\n",
        "- Context-aware responses\n",
        "- State management with MemorySaver\n",
        "- Uses free Gemini API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOzvkAKPCbTD",
        "outputId": "1f9cead9-6453-4cbb-f153-e6c7ba557d8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Agent: That's a great choice! Blue is a very popular and versatile color. What do you like about blue?\n",
            "Agent: You told me earlier that your favorite color is blue!\n"
          ]
        }
      ],
      "source": [
        "# Create a simple memory-based agent\n",
        "from langgraph.graph import StateGraph, END\n",
        "from typing import Annotated, TypedDict\n",
        "import operator\n",
        "\n",
        "# Define the state for our agent\n",
        "class AgentState(TypedDict):\n",
        "   messages: Annotated[list, operator.add]\n",
        "\n",
        "# Create a simple agent that remembers context\n",
        "def memory_agent(state: AgentState):\n",
        "   # Get the last message\n",
        "   last_message = state[\"messages\"][-1]\n",
        "\n",
        "   # Convert messages to string format for context\n",
        "   context_str = \"\\n\".join([f\"{msg.__class__.__name__}: {msg.content}\" for msg in state[\"messages\"]])\n",
        "\n",
        "   # Generate a response based on all previous messages\n",
        "   prompt = f\"Context of conversation:\\n{context_str}\\n\\nCurrent message: {last_message.content}\\n\\nResponse:\"\n",
        "   response = llm.invoke(prompt)\n",
        "\n",
        "   return {\"messages\": [AIMessage(content=response.content)]}\n",
        "\n",
        "# Create the graph\n",
        "memory_graph = StateGraph(AgentState)\n",
        "memory_graph.add_node(\"agent\", memory_agent)\n",
        "memory_graph.set_entry_point(\"agent\")\n",
        "memory_graph.add_edge(\"agent\", END)\n",
        "\n",
        "# Compile with checkpointer for memory\n",
        "memory_checkpointer = MemorySaver()\n",
        "memory_compiled = memory_graph.compile(checkpointer=memory_checkpointer)\n",
        "\n",
        "# Test the memory agent\n",
        "config = {\"configurable\": {\"thread_id\": \"test_thread\"}}\n",
        "result = memory_compiled.invoke(\n",
        "   {\"messages\": [HumanMessage(content=\"My favorite color is blue\")]},\n",
        "   config=config\n",
        ")\n",
        "print(\"Agent:\", result[\"messages\"][-1].content)\n",
        "\n",
        "# Test that it remembers\n",
        "result2 = memory_compiled.invoke(\n",
        "   {\"messages\": [HumanMessage(content=\"What's my favorite color?\")]},\n",
        "   config=config\n",
        ")\n",
        "print(\"Agent:\", result2[\"messages\"][-1].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dveGit11EyZr"
      },
      "source": [
        "## 2. Tool-using Agent\n",
        "\n",
        "This pattern demonstrates an agent that can use external tools to perform tasks. The agent uses Wikipedia as an example tool to retrieve information when needed.\n",
        "\n",
        "Key features:\n",
        "- Tool integration with LangGraph\n",
        "- React-style reasoning (Thought-Action-Observation)\n",
        "- Dynamic tool selection based on user queries\n",
        "- Free Wikipedia API integration"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install wikipedia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOcKbugNkPhX",
        "outputId": "571039e0-f40b-4cd8-8f71-0ff408f0e1be"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from wikipedia) (4.13.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wikipedia) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2025.4.26)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->wikipedia) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->wikipedia) (4.13.2)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11678 sha256=cac038d4b9855a3fa42d646a400499f737093daa5426209fb40f00003bb8290a\n",
            "  Stored in directory: /root/.cache/pip/wheels/8f/ab/cb/45ccc40522d3a1c41e1d2ad53b8f33a62f394011ec38cd71c6\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UHmIctdEaNT",
        "outputId": "f3b180fc-0e66-4506-9fcd-e6b7886398db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
            "\n",
            "The code that caused this warning is on line 389 of the file /usr/local/lib/python3.11/dist-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
            "\n",
            "  lis = BeautifulSoup(html).find_all('li')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tool Agent: I searched for 'Newton' and found:\n",
            "\n",
            "Page: Isaac Newton\n",
            "Summary: Sir Isaac Newton (; 4 January [O.S. 25 December] 1643 – 31 March [O.S. 20 March] 1727) was an English polymath active as a mathematician, physicist, astronomer, alchemist, theologian, and author. Newton was a key figure in the Scientific Revolution and the Enlightenment that followed. His book Philosophiæ Naturalis Principia Mathematica (Mathematical Principles of Natural Philosophy), first published in 1687, achieved the first great unification in physics and established classical mechanics. Newton also made seminal contributions to optics, and shares credit with German mathematician Gottfried Wilhelm Leibniz for formulating infinitesimal calculus, though he developed calculus years before Leibniz. Newton contributed to and refined the scientific method, and his work is considered the most influential in bringing forth modern science.\n",
            "In the Principia, Newton formulated the laws of motion and universal gravitation that formed the dominant scientific viewpoint for centuries until it was superseded by the theory of relativity. He used his mathematical description of gravity to derive Kepler's laws of planetary motion, account for tides, the trajectories of comets, the precession of the equinoxes and other phenomena, eradicating doubt about the Solar System's heliocentricity. Newton solved the two-body problem, and introduced the three-body problem. He demonstrated that the motion of objects on Earth and celestial bodies could be accounted for by the same principles. Newton's inference that the Earth is an oblate spheroid was later confirmed by the geodetic measurements of Maupertuis, La Condamine, and others, thereby convincing most European scientists of the superiority of Newtonian mechanics over earlier systems. Newton was also the first to calculate the age of Earth by experiment, and described a precursor to the modern wind tunnel.\n",
            "Newton built the first reflecting telescope and developed a sophisticated theory of colour based on the observation that a prism separates white light into the colours of the visible spectrum. His work on light was collected in his book Opticks, published in 1704. He originated prisms as beam expanders and multiple-prism arrays, which would later become integral to the development of tunable lasers. He also anticipated wave–particle duality and was the first to theorize the Goos–Hänchen effect. He further formulated an empirical law of cooling, which was the first heat transfer formulation and serves as the formal basis of convective heat transfer, made the first theoretical calculation of the speed of sound, and introduced the notions of a Newtonian fluid and a black body. He was also the first to explain the Magnus effect. Furthermore, he made early studies into electricity. In addition to his creation of calculus, Newton's work on mathematics was extensive. He generalized the binomial theorem to any real number, introduced the Puiseux series, was the first to state Bézout's theorem, classified most of the cubic plane curves, contributed to the study of Cremona transformations, developed a method for approximating the roots of a function, and also originated the Newton–Cotes formulas for numerical integration. He further initiated the field of calculus of variations, devised an early form of regression analysis, and was a pioneer of vector analysis.\n",
            "Newton was a fellow of Trinity College and the second Lucasian Professor of Mathematics at the University of Cambridge; he was appointed at the age of 26. He was a devout but unorthodox Christian who privately rejected the doctrine of the Trinity. He refused to take holy orders in the Church of England, unlike most members of the Cambridge faculty of the day. Beyond his work on the mathematical sciences, Newton dedicated much of his time to the study of alchemy and biblical chronology, but most of his work in those areas remained unpublished until long after his death. Politically and personally tied to the Whig party, N\n",
            "Tool Agent: Why don't scientists trust atoms?\n",
            "\n",
            "Because they make up everything!\n"
          ]
        }
      ],
      "source": [
        "from typing import TypedDict, Annotated\n",
        "import operator\n",
        "\n",
        "# Create Wikipedia tool\n",
        "wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
        "\n",
        "# Define tool-using agent state\n",
        "class ToolState(TypedDict):\n",
        "   messages: Annotated[list, operator.add]\n",
        "\n",
        "def tool_agent(state: ToolState):\n",
        "   messages = state[\"messages\"]\n",
        "   last_message = messages[-1]\n",
        "\n",
        "   # Create a simple tool-using agent\n",
        "   if \"search\" in last_message.content.lower() or \"find\" in last_message.content.lower():\n",
        "       # Extract search query\n",
        "       search_query = last_message.content.replace(\"search for\", \"\").replace(\"find\", \"\").strip()\n",
        "\n",
        "       # Use Wikipedia tool\n",
        "       search_result = wikipedia.run(search_query)\n",
        "\n",
        "       response = f\"I searched for '{search_query}' and found:\\n\\n{search_result}\"\n",
        "   else:\n",
        "       # Regular response\n",
        "       response = llm.invoke(last_message.content)\n",
        "       response = response.content\n",
        "\n",
        "   return {\"messages\": [AIMessage(content=response)]}\n",
        "\n",
        "# Create tool agent graph\n",
        "tool_graph = StateGraph(ToolState)\n",
        "tool_graph.add_node(\"agent\", tool_agent)\n",
        "tool_graph.set_entry_point(\"agent\")\n",
        "tool_graph.add_edge(\"agent\", END)\n",
        "\n",
        "# Compile and test\n",
        "tool_compiled = tool_graph.compile()\n",
        "\n",
        "# Test tool usage\n",
        "result = tool_compiled.invoke({\"messages\": [HumanMessage(content=\"search for Newton\")]})\n",
        "print(\"Tool Agent:\", result[\"messages\"][-1].content)\n",
        "\n",
        "# Test normal conversation\n",
        "result2 = tool_compiled.invoke({\"messages\": [HumanMessage(content=\"Tell me a joke\")]})\n",
        "print(\"Tool Agent:\", result2[\"messages\"][-1].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCWCMQM7E61h"
      },
      "source": [
        "## 3. Multi-agent Collaboration\n",
        "\n",
        "This pattern shows how multiple specialized agents can work together on a task. Each agent has a specific role and they pass information between themselves to complete complex tasks.\n",
        "\n",
        "Key features:\n",
        "- Multiple specialized agents\n",
        "- Agent collaboration workflow\n",
        "- State sharing between agents\n",
        "- Task delegation and coordination"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiIopRKUE4dg",
        "outputId": "c26f1830-a2d9-47b8-be0c-e5915c6c8593"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multi-Agent Result:\n",
            "HumanMessage: research about quantum computing\n",
            "AIMessage: Research findings: Page: Quantum computing\n",
            "Summary: A quantum computer is a computer that exploits quantum mechanical phenomena. On small scales, physical matter exhibits properties of both particles and waves, and quantum computing takes advantage of this behavior using specialized hardware. Classical physics cannot explain the operation of these quantum devices, and a scalable quantum computer could perform some calculations exponentially faster than any modern \"classical\" computer. Theoretically a large-scale quantum computer could break some widely used encryption schemes and aid physicists in performing physical simulations; however, the current state of the art is largely experimental and impractical, with several obstacles to useful applications.\n",
            "The basic unit of information in quantum computing, the qubit (or \"quantum bit\"), serves the same function as the bit in classical computing. However, unlike a classical bit, which can be in one of two states (a binary), a qubit can exist in a superposition of its two \"basis\" states, a state that is in an abstract sense \"between\" the two basis states. When measuring a qubit, the result is a probabilistic output of a classical bit. If a quantum computer manipulates the qubit in a particular way, wave interference effects can amplify the desired measurement results. The design of quantum algorithms involves creating procedures that allow a quantum computer to perform calculations efficiently and quickly.\n",
            "Quantum computers are not yet practical for real-world applications. Physically engineering high-quality qubits has proven to be challenging. If a physical qubit is not sufficiently isolated from its environment, it suffers from quantum decoherence, introducing noise into calculations. National governments have invested heavily in experimental research aimed at developing  scalable qubits with longer coherence times and lower error rates. Example implementations include superconductors (which isolate an electrical current by eliminating electrical resistance) and ion traps (which confine a single atomic particle using electromagnetic fields).\n",
            "In principle, a classical computer can solve the same computational problems as a quantum computer, given enough time. Quantum advantage comes in the form of time complexity rather than computability, and quantum complexity theory shows that some quantum algorithms are exponentially more efficient than the best-known classical algorithms. A large-scale quantum computer could in theory solve computational problems that are not solvable within a reasonable timeframe for a classical computer. This concept of additional ability has been called \"quantum supremacy\". While such claims have drawn significant attention to the discipline, near-term practical use cases remain limited.\n",
            "\n",
            "\n",
            "\n",
            "Page: Timeline of quantum computing and communication\n",
            "Summary: This is a timeline of quantum computing.\n",
            "\n",
            "Page: Superconducting quantum computing\n",
            "Summary: Superconducting quantum computing is a branch of solid state  physics and quantum computing that implements superconducting electronic circuits using superconducting qubits as artificial atoms, or quantum dots. For superconducting qubits, the two logic states are the ground state and the excited state, denoted \n",
            "  \n",
            "    \n",
            "      \n",
            "        \n",
            "          |\n",
            "        \n",
            "        g\n",
            "        ⟩\n",
            "        \n",
            "           and \n",
            "        \n",
            "        \n",
            "          |\n",
            "        \n",
            "        e\n",
            "        ⟩\n",
            "      \n",
            "    \n",
            "    {\\displaystyle |g\\rangle {\\text{ and }}|e\\rangle }\n",
            "  \n",
            " respectively. Research in superconducting quantum computing is conducted by companies such as Google, IBM, IMEC, BBN Technologies, Rigetti, and Intel.  Many recently developed QPUs (quantum processing units, or quantum chips) use superconducting architecture.\n",
            "As of May 2016, up to 9 fully controllable qubits are demonstrated in the 1D array, and up to 16 in 2D architecture. In October 2019, the Martinis group, partnered with Google, published an article demonstrating novel quantum supremacy, using a chip composed \n",
            "AIMessage: Quantum computing utilizes quantum mechanical phenomena like superposition to perform computations. Qubits, the basic unit of information, can exist in a superposition of states, allowing for potentially exponential speedups compared to classical computers for certain problems. While theoretically powerful enough to break encryption and aid in simulations, current quantum computers are experimental and face challenges like quantum decoherence. Superconducting quantum computing is a leading implementation approach, with companies like Google and IBM developing quantum processors using superconducting qubits. Despite progress, practical applications and \"quantum supremacy\" remain limited in the near term.\n"
          ]
        }
      ],
      "source": [
        "# Define multi-agent state\n",
        "class MultiAgentState(TypedDict):\n",
        "   messages: Annotated[list, operator.add]\n",
        "   task_type: str\n",
        "   current_agent: str\n",
        "   result: str\n",
        "\n",
        "# Create specialized agents\n",
        "def researcher_agent(state: MultiAgentState):\n",
        "   \"\"\"Researches information using Wikipedia\"\"\"\n",
        "   task = state[\"messages\"][-1].content\n",
        "\n",
        "   if \"research\" in task.lower() or \"find information\" in task.lower():\n",
        "       search_query = task.split(\"about\")[-1].strip() if \"about\" in task else task\n",
        "       research_result = wikipedia.run(search_query)\n",
        "\n",
        "       response = f\"Research findings: {research_result}\"\n",
        "       return {\"messages\": [AIMessage(content=response)], \"current_agent\": \"writer\", \"result\": research_result}\n",
        "\n",
        "   return {\"messages\": [AIMessage(content=\"No research task identified\")], \"current_agent\": \"done\"}\n",
        "\n",
        "def writer_agent(state: MultiAgentState):\n",
        "   \"\"\"Writes content based on research\"\"\"\n",
        "   research_result = state.get(\"result\", \"\")\n",
        "\n",
        "   if research_result:\n",
        "       prompt = f\"Based on this research: {research_result}\\n\\nWrite a brief summary:\"\n",
        "       response = llm.invoke(prompt)\n",
        "       return {\"messages\": [AIMessage(content=response.content)], \"current_agent\": \"done\"}\n",
        "\n",
        "   return {\"messages\": [AIMessage(content=\"No research data to write from\")], \"current_agent\": \"done\"}\n",
        "\n",
        "# Create multi-agent workflow\n",
        "multi_agent_graph = StateGraph(MultiAgentState)\n",
        "multi_agent_graph.add_node(\"researcher\", researcher_agent)\n",
        "multi_agent_graph.add_node(\"writer\", writer_agent)\n",
        "\n",
        "# Set entry point\n",
        "multi_agent_graph.set_entry_point(\"researcher\")\n",
        "\n",
        "# Add conditional edges\n",
        "def router(state: MultiAgentState):\n",
        "   if state[\"current_agent\"] == \"writer\":\n",
        "       return \"writer\"\n",
        "   else:\n",
        "       return END\n",
        "\n",
        "multi_agent_graph.add_conditional_edges(\"researcher\", router, {\"writer\": \"writer\", END: END})\n",
        "multi_agent_graph.add_edge(\"writer\", END)\n",
        "\n",
        "# Compile and test\n",
        "multi_agent = multi_agent_graph.compile()\n",
        "\n",
        "# Test multi-agent collaboration\n",
        "result = multi_agent.invoke({\n",
        "   \"messages\": [HumanMessage(content=\"research about quantum computing\")],\n",
        "   \"task_type\": \"research_and_write\",\n",
        "   \"current_agent\": \"researcher\",\n",
        "   \"result\": \"\"\n",
        "})\n",
        "\n",
        "print(\"Multi-Agent Result:\")\n",
        "for msg in result[\"messages\"]:\n",
        "   print(f\"{msg.__class__.__name__}: {msg.content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHWCPft3FVDJ"
      },
      "source": [
        "## 4. Planning Agent\n",
        "\n",
        "This pattern demonstrates an agent that can break down complex tasks into steps and execute them systematically. The planning agent creates a plan of action and then executes each step sequentially.\n",
        "\n",
        "Key features:\n",
        "- Task decomposition\n",
        "- Sequential execution\n",
        "- Step-by-step tracking\n",
        "- Goal-oriented behavior"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define planning agent state\n",
        "class PlanningState(TypedDict):\n",
        "   messages: Annotated[list, operator.add]\n",
        "   plan: list\n",
        "   current_step: int\n",
        "   step_results: list"
      ],
      "metadata": {
        "id": "EaP1rTqIkeze"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def planning_agent(state: PlanningState):\n",
        "   \"\"\"Creates a plan for complex tasks\"\"\"\n",
        "   task = state[\"messages\"][-1].content\n",
        "\n",
        "   # Generate a plan\n",
        "   prompt = f\"\"\"Break down this task into 3-5 simple steps: {task}\n",
        "\n",
        "Format your response as a numbered list:\n",
        "1. [step]\n",
        "2. [step]\n",
        "3. [step]\"\"\"\n",
        "\n",
        "   plan_response = llm.invoke(prompt)\n",
        "\n",
        "   # Extract plan steps\n",
        "   plan_text = plan_response.content\n",
        "   steps = []\n",
        "   for line in plan_text.split('\\n'):\n",
        "       if line.strip() and any(line.strip().startswith(str(i)) for i in range(1, 6)):\n",
        "           steps.append(line.strip())\n",
        "\n",
        "   return {\n",
        "       \"messages\": [AIMessage(content=f\"Created plan:\\n{plan_text}\")],\n",
        "       \"plan\": steps,\n",
        "       \"current_step\": 0,\n",
        "       \"step_results\": []\n",
        "   }"
      ],
      "metadata": {
        "id": "0i0-jezokg08"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLS6JdKkFSrM",
        "outputId": "736e9c5b-7575-41fa-f152-d9ecbe2bed59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Planning Agent Results:\n",
            "\n",
            "HumanMessage: Plan and execute: Create a simple chatbot\n",
            "\n",
            "AIMessage: Created plan:\n",
            "Here's a breakdown of planning and executing a simple chatbot:\n",
            "\n",
            "1. **Define the Chatbot's Purpose & Scope:** Decide what your chatbot will *do*. Will it answer FAQs, schedule appointments, provide basic information, or something else? Keep it very narrow and simple for a first project.  Determine the key questions/topics it needs to handle.\n",
            "\n",
            "2. **Choose a Platform/Tool & Build the Basic Structure:** Select a chatbot platform (e.g., Dialogflow, Rasa, Microsoft Bot Framework, or even a simple Python script).  Create the basic structure:  define intents (user goals), entities (key information), and responses for the most common user inputs.\n",
            "\n",
            "3. **Train & Test Your Chatbot:**  Provide example phrases for each intent and test the chatbot with different inputs. Refine the responses and add more training data to improve accuracy and handle edge cases.\n",
            "\n",
            "AIMessage: Executed: 1. **Define the Chatbot's Purpose & Scope:** Decide what your chatbot will *do*. Will it answer FAQs, schedule appointments, provide basic information, or something else? Keep it very narrow and simple for a first project.  Determine the key questions/topics it needs to handle.\n",
            "Result: **Chatbot Purpose & Scope:**\n",
            "\n",
            "*   **Purpose:** Answer frequently asked questions about a local library's operating hours and location.\n",
            "*   **Scope:** Limited to providing information on library hours, address, and a simple greeting.\n",
            "*   **Key Questions/Topics:**\n",
            "    *   \"What are your hours?\"\n",
            "    *   \"Where are you located?\"\n",
            "    *   \"What is the library's address?\"\n",
            "    *   \"Hello\" / \"Hi\" (basic greeting)\n",
            "\n",
            "AIMessage: Executed: 2. **Choose a Platform/Tool & Build the Basic Structure:** Select a chatbot platform (e.g., Dialogflow, Rasa, Microsoft Bot Framework, or even a simple Python script).  Create the basic structure:  define intents (user goals), entities (key information), and responses for the most common user inputs.\n",
            "Result: Okay, I'll execute step 2 and provide a brief result.\n",
            "\n",
            "**Platform Choice:** I'll choose **Dialogflow** because it's a user-friendly, cloud-based platform suitable for prototyping and has a good balance of features and ease of use.\n",
            "\n",
            "**Basic Structure (Example - Coffee Ordering Bot):**\n",
            "\n",
            "*   **Intent: `OrderCoffee`**\n",
            "    *   **User Input Examples:**\n",
            "        *   \"I want to order a coffee.\"\n",
            "        *   \"Can I get a latte?\"\n",
            "        *   \"I'd like a cappuccino, please.\"\n",
            "    *   **Entities:**\n",
            "        *   `@coffeeType` (e.g., latte, cappuccino, espresso)\n",
            "        *   `@quantity` (e.g., one, two, a couple)\n",
            "        *   `@size` (e.g., small, medium, large)\n",
            "    *   **Response:**\n",
            "        *   \"Okay, I understand you want to order a `@quantity` `@size` `@coffeeType`. Is that correct?\" (This can prompt for confirmation and handle missing entity values).\n",
            "        *   (Alternatively, if all information is present) \"Great! I've added a `@quantity` `@size` `@coffeeType` to your order.\"\n",
            "\n",
            "*   **Intent: `Greetings`**\n",
            "    *   **User Input Examples:**\n",
            "        *   \"Hello\"\n",
            "        *   \"Hi\"\n",
            "        *   \"Good morning\"\n",
            "    *   **Entities:** (None needed)\n",
            "    *   **Response:**\n",
            "        *   \"Hello! How can I help you today?\"\n",
            "        *   \"Hi there! Ready to order some coffee?\"\n",
            "\n",
            "*   **Intent: `Goodbye`**\n",
            "    *   **User Input Examples:**\n",
            "        *   \"Goodbye\"\n",
            "        *   \"Bye\"\n",
            "        *   \"Thanks, that's all.\"\n",
            "    *   **Entities:** (None needed)\n",
            "    *   **Response:**\n",
            "        *   \"Goodbye!\"\n",
            "        *   \"Have a great day!\"\n",
            "\n",
            "**Brief Result:**\n",
            "\n",
            "I have chosen Dialogflow as the platform and defined three basic intents: `OrderCoffee`, `Greetings`, and `Goodbye`. For the `OrderCoffee` intent, I've identified key entities like `@coffeeType`, `@quantity`, and `@size` to extract relevant information from user inputs. I've also created simple responses for each intent to initiate and conclude conversations. This forms the very basic structure of a coffee ordering chatbot.\n",
            "\n",
            "AIMessage: Executed: 3. **Train & Test Your Chatbot:**  Provide example phrases for each intent and test the chatbot with different inputs. Refine the responses and add more training data to improve accuracy and handle edge cases.\n",
            "Result: Okay, let's assume we've already defined our intents and entities (as would be done in steps 1 and 2).  Let's say we have the following intents:\n",
            "\n",
            "*   **`Greeting`**: Handles greetings.\n",
            "*   **`OrderPizza`**: Handles ordering a pizza.\n",
            "*   **`OrderStatus`**: Handles checking the status of an order.\n",
            "*   **`Goodbye`**: Handles farewells.\n",
            "\n",
            "**3. Train & Test Your Chatbot (Example using a hypothetical chatbot platform):**\n",
            "\n",
            "**A. Training Data (Example Phrases):**\n",
            "\n",
            "*   **`Greeting`**:\n",
            "    *   \"Hi\"\n",
            "    *   \"Hello\"\n",
            "    *   \"Good morning\"\n",
            "    *   \"Hey there\"\n",
            "    *   \"How's it going?\"\n",
            "\n",
            "*   **`OrderPizza`**:\n",
            "    *   \"I want to order a pizza\"\n",
            "    *   \"Can I get a pizza delivered?\"\n",
            "    *   \"I'd like to place a pizza order\"\n",
            "    *   \"Order a large pepperoni pizza\" (This would require an entity for pizza type and size)\n",
            "    *   \"I want a pizza with mushrooms and olives\" (This would require entities for toppings)\n",
            "\n",
            "*   **`OrderStatus`**:\n",
            "    *   \"What's the status of my order?\"\n",
            "    *   \"Where's my pizza?\"\n",
            "    *   \"Has my order shipped yet?\"\n",
            "    *   \"Check my order status\"\n",
            "    *   \"What is the ETA on my pizza?\"\n",
            "\n",
            "*   **`Goodbye`**:\n",
            "    *   \"Bye\"\n",
            "    *   \"Goodbye\"\n",
            "    *   \"See you later\"\n",
            "    *   \"Thanks, bye\"\n",
            "    *   \"I'm done, thank you\"\n",
            "\n",
            "**B. Initial Testing and Refinement:**\n",
            "\n",
            "Let's imagine we feed this data into a chatbot platform (like Dialogflow, Rasa, or LUIS).  After training, we might test with the following inputs:\n",
            "\n",
            "*   **Input:** \"Hey\"\n",
            "    *   **Expected Intent:** `Greeting`\n",
            "    *   **Actual Result:** `Greeting` (Success!)\n",
            "    *   **Response:** \"Hello! How can I help you today?\"\n",
            "\n",
            "*   **Input:** \"I want a large pizza\"\n",
            "    *   **Expected Intent:** `OrderPizza`\n",
            "    *   **Actual Result:** `OrderPizza` (Success!)\n",
            "    *   **Response:** \"What kind of pizza would you like?\" (If we have a pizza type entity) OR \"Okay, what toppings would you like?\" (If we don't have pizza types but do have toppings.)\n",
            "\n",
            "*   **Input:** \"Is my pizza here yet?\"\n",
            "    *   **Expected Intent:** `OrderStatus`\n",
            "    *   **Actual Result:** `OrderStatus` (Success!)\n",
            "    *   **Response:** \"Please provide your order number.\"\n",
            "\n",
            "*   **Input:** \"I'm good, thanks\"\n",
            "    *   **Expected Intent:** `Goodbye`\n",
            "    *   **Actual Result:** `Goodbye` (Success!)\n",
            "    *   **Response:** \"You're welcome! Have a great day!\"\n",
            "\n",
            "*   **Input:** \"Give me a veggie pizza\"\n",
            "    *   **Expected Intent:** `OrderPizza`\n",
            "    *   **Actual Result:** `OrderPizza` (Success!)\n",
            "    *   **Response:** \"Okay, I will add a veggie pizza to your order\"\n",
            "\n",
            "**C. Edge Case Testing and Refinement:**\n",
            "\n",
            "Let's see how it handles less obvious cases:\n",
            "\n",
            "*   **Input:** \"Hey, I ordered a pizza an hour ago.\"\n",
            "    *   **Expected Intent:** `OrderStatus` (potentially also `Greeting`)\n",
            "    *   **Actual Result:** `Greeting` or `OrderPizza` (depending on how the platform prioritizes intents). This is ambiguous.\n",
            "    *   **Refinement:** Add training phrases to `OrderStatus` like \"I ordered a pizza an hour ago\", \"Where is the pizza I ordered?\"  Consider adjusting intent priorities in the platform.\n",
            "\n",
            "*   **Input:** \"Large pizza with pepperoni and pineapple\"\n",
            "    *   **Expected Intent:** `OrderPizza`\n",
            "    *   **Actual Result:** `OrderPizza` (Success!)\n",
            "    *   **Response:** \"Adding large pizza with pepperoni and pineapple to your order.\"\n",
            "\n",
            "*   **Input:** \"I want to cancel my pizza\"\n",
            "    *   **Expected Intent:** *Missing!* We didn't define a `CancelOrder` intent.\n",
            "    *   **Refinement:** Create a `CancelOrder` intent and add training phrases like \"Cancel my order\", \"I want to cancel my pizza\", \"Please cancel my order\".\n",
            "\n",
            "**Brief Result:**\n",
            "\n",
            "The initial chatbot performs reasonably well with straightforward input. However, it struggles with ambiguous phrases and lacks the ability to handle order cancellations. Further training and the addition of a `CancelOrder` intent are required to improve accuracy and robustness. We need to continue adding examples and edge cases to refine the chatbot.\n"
          ]
        }
      ],
      "source": [
        "def execute_step(state: PlanningState):\n",
        "   \"\"\"Executes the current step in the plan\"\"\"\n",
        "   if state[\"current_step\"] >= len(state[\"plan\"]):\n",
        "       final_summary = \"\\n\".join(state[\"step_results\"])\n",
        "       return {\n",
        "           \"messages\": [AIMessage(content=f\"Plan completed. Results:\\n{final_summary}\")],\n",
        "           \"current_step\": state[\"current_step\"]\n",
        "       }\n",
        "\n",
        "   current_step = state[\"plan\"][state[\"current_step\"]]\n",
        "\n",
        "   # Execute current step\n",
        "   prompt = f\"Execute this step: {current_step}\\nProvide a brief result.\"\n",
        "   result = llm.invoke(prompt)\n",
        "\n",
        "   return {\n",
        "       \"messages\": [AIMessage(content=f\"Executed: {current_step}\\nResult: {result.content}\")],\n",
        "       \"current_step\": state[\"current_step\"] + 1,\n",
        "       \"step_results\": state[\"step_results\"] + [f\"Step {state['current_step'] + 1}: {result.content}\"]\n",
        "   }\n",
        "\n",
        "# Create planning agent workflow\n",
        "planning_graph = StateGraph(PlanningState)\n",
        "planning_graph.add_node(\"planner\", planning_agent)\n",
        "planning_graph.add_node(\"executor\", execute_step)\n",
        "\n",
        "planning_graph.set_entry_point(\"planner\")\n",
        "planning_graph.add_edge(\"planner\", \"executor\")\n",
        "\n",
        "# Add loop for executing all steps\n",
        "def should_continue(state: PlanningState):\n",
        "   if state[\"current_step\"] >= len(state[\"plan\"]):\n",
        "       return END\n",
        "   return \"executor\"\n",
        "\n",
        "planning_graph.add_conditional_edges(\"executor\", should_continue, {\"executor\": \"executor\", END: END})\n",
        "\n",
        "# Compile and test\n",
        "planning_compiled = planning_graph.compile()\n",
        "\n",
        "# Test planning agent\n",
        "result = planning_compiled.invoke({\n",
        "   \"messages\": [HumanMessage(content=\"Plan and execute: Create a simple chatbot\")],\n",
        "   \"plan\": [],\n",
        "   \"current_step\": 0,\n",
        "   \"step_results\": []\n",
        "})\n",
        "\n",
        "print(\"Planning Agent Results:\")\n",
        "for msg in result[\"messages\"]:\n",
        "   print(f\"\\n{msg.__class__.__name__}: {msg.content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbKwswSpFiI_"
      },
      "source": [
        "## Summary and Testing\n",
        "\n",
        "Let's create a simple test dashboard to demonstrate all agent patterns and visualize their execution flow:\n",
        "\n",
        "- Memory-based Agent: Maintains conversation context\n",
        "- Tool-using Agent: Integrates external APIs\n",
        "- Multi-agent Collaboration: Coordinates multiple specialized agents\n",
        "- Planning Agent: Breaks down and executes complex tasks\n",
        "\n",
        "This completes the LangGraph implementation. For the CrewAI implementation, we'll need to structure the patterns differently using CrewAI's framework."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a simple memory-based agent\n",
        "from langgraph.graph import StateGraph, END\n",
        "from typing import Annotated, TypedDict\n",
        "import operator\n",
        "\n",
        "# Define the state for our agent\n",
        "class AgentState(TypedDict):\n",
        "   messages: Annotated[list, operator.add]\n",
        "\n",
        "# Create a simple agent that remembers context\n",
        "def memory_agent(state: AgentState):\n",
        "   # Get the last message\n",
        "   last_message = state[\"messages\"][-1]\n",
        "\n",
        "   # Convert messages to string format for context\n",
        "   context_str = \"\\n\".join([f\"{msg.__class__.__name__}: {msg.content}\" for msg in state[\"messages\"]])\n",
        "\n",
        "   # Generate a response based on all previous messages\n",
        "   prompt = f\"Context of conversation:\\n{context_str}\\n\\nCurrent message: {last_message.content}\\n\\nResponse:\"\n",
        "   response = llm.invoke(prompt)\n",
        "\n",
        "   return {\"messages\": [AIMessage(content=response.content)]}\n",
        "\n",
        "# Create the graph\n",
        "memory_graph = StateGraph(AgentState)\n",
        "memory_graph.add_node(\"agent\", memory_agent)\n",
        "memory_graph.set_entry_point(\"agent\")\n",
        "memory_graph.add_edge(\"agent\", END)\n",
        "\n",
        "# Compile with checkpointer for memory\n",
        "memory_checkpointer = MemorySaver()\n",
        "memory_compiled = memory_graph.compile(checkpointer=memory_checkpointer)\n",
        "\n",
        "# Test the memory agent\n",
        "config = {\"configurable\": {\"thread_id\": \"test_thread\"}}\n",
        "result = memory_compiled.invoke(\n",
        "   {\"messages\": [HumanMessage(content=\"My favorite color is blue\")]},\n",
        "   config=config\n",
        ")\n",
        "print(\"Agent:\", result[\"messages\"][-1].content)\n",
        "\n",
        "# Test that it remembers\n",
        "result2 = memory_compiled.invoke(\n",
        "   {\"messages\": [HumanMessage(content=\"What's my favorite color?\")]},\n",
        "   config=config\n",
        ")\n",
        "print(\"Agent:\", result2[\"messages\"][-1].content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r411LR3tkxqC",
        "outputId": "1c55822d-90b9-41ba-c83c-e0f9efd5cf97"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent: That's cool! What shade of blue do you like best?\n",
            "Agent: You told me your favorite color is blue.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a test dashboard to demonstrate all patterns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "# Create visualization of agent patterns\n",
        "fig = plt.figure(figsize=(15, 10))\n",
        "gs = gridspec.GridSpec(2, 2, figure=fig)\n",
        "\n",
        "# Test all patterns and visualize\n",
        "patterns = {\n",
        "   \"Memory Agent\": memory_compiled,\n",
        "   \"Tool Agent\": tool_compiled,\n",
        "   \"Multi-Agent\": multi_agent,\n",
        "   \"Planning Agent\": planning_compiled\n",
        "}\n",
        "\n",
        "test_queries = {\n",
        "   \"Memory Agent\": [\"My name is Alice\", \"What's my name?\"],\n",
        "   \"Tool Agent\": [\"search for Python programming\"],\n",
        "   \"Multi-Agent\": [\"research about machine learning\"],\n",
        "   \"Planning Agent\": [\"Plan: write a blog post about AI\"]\n",
        "}\n",
        "\n",
        "results = {}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dvhRzlcsklzG",
        "outputId": "83c20053-0e7a-4836-d501-4943996884a9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x1000 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "tDi6HvD9FgzG",
        "outputId": "1470ea84-c3af-418f-820a-95b37b1183e3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== LangGraph Agent Patterns Summary ===\n",
            "\n",
            "Memory Agent:\n",
            "  Response 1: Okay, it seems like you're repeating yourself. Is there anything else I can help you with, Alice?...\n",
            "  Response 2: You told me your name is Alice....\n",
            "\n",
            "Tool Agent:\n",
            "  Response 1: I searched for 'Python programming' and found:\n",
            "\n",
            "Page: Python (programming language)\n",
            "Summary: Python is a high-level, general-purpose programming language. Its design philosophy emphasizes code readabi...\n",
            "\n",
            "Multi-Agent:\n",
            "  Response 1: Research findings: Page: Machine learning\n",
            "Summary: Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can lear...\n",
            "  Response 2: Machine learning (ML) is a field of AI where statistical algorithms learn from data to perform tasks without explicit instructions. Deep learning, a subfield of ML, utilizes neural networks to achieve...\n",
            "\n",
            "Planning Agent:\n",
            "  Response 1: Created plan:\n",
            "Here's a breakdown of planning a blog post about AI into 3 simple steps:\n",
            "\n",
            "1. **Choose a Specific AI Topic & Angle:** Don't just say \"AI.\" Narrow it down. Examples: \"AI for Beginners,\" \"T...\n",
            "  Response 2: Executed: 1. **Choose a Specific AI Topic & Angle:** Don't just say \"AI.\" Narrow it down. Examples: \"AI for Beginners,\" \"The Ethics of AI Art,\" \"AI's Impact on Marketing,\" \"5 AI Tools to Boost Product...\n",
            "  Response 3: Executed: 2. **Outline Your Key Points & Structure:** Decide on the main points you want to cover. Create a basic outline with a clear introduction, body paragraphs (each addressing a specific point),...\n",
            "  Response 4: Executed: 3. **Research & Gather Information:** Once you have your topic and outline, research relevant information from credible sources. This could include articles, studies, examples, or expert opi...\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Test each pattern\n",
        "for pattern_name, agent in patterns.items():\n",
        "   if pattern_name == \"Memory Agent\":\n",
        "       config = {\"configurable\": {\"thread_id\": \"demo_thread\"}}\n",
        "       result1 = agent.invoke({\"messages\": [HumanMessage(content=test_queries[pattern_name][0])]}, config=config)\n",
        "       result2 = agent.invoke({\"messages\": [HumanMessage(content=test_queries[pattern_name][1])]}, config=config)\n",
        "       results[pattern_name] = [result1[\"messages\"][-1].content, result2[\"messages\"][-1].content]\n",
        "   else:\n",
        "       if pattern_name == \"Multi-Agent\":\n",
        "           result = agent.invoke({\n",
        "               \"messages\": [HumanMessage(content=test_queries[pattern_name][0])],\n",
        "               \"task_type\": \"research_and_write\",\n",
        "               \"current_agent\": \"researcher\",\n",
        "               \"result\": \"\"\n",
        "           })\n",
        "           results[pattern_name] = [msg.content for msg in result[\"messages\"] if isinstance(msg, AIMessage)]\n",
        "       elif pattern_name == \"Planning Agent\":\n",
        "           result = agent.invoke({\n",
        "               \"messages\": [HumanMessage(content=test_queries[pattern_name][0])],\n",
        "               \"plan\": [],\n",
        "               \"current_step\": 0,\n",
        "               \"step_results\": []\n",
        "           })\n",
        "           results[pattern_name] = [msg.content for msg in result[\"messages\"] if isinstance(msg, AIMessage)]\n",
        "       else:\n",
        "           result = agent.invoke({\"messages\": [HumanMessage(content=test_queries[pattern_name][0])]})\n",
        "           results[pattern_name] = [result[\"messages\"][-1].content]\n",
        "\n",
        "# Display results\n",
        "for i, (pattern_name, pattern_results) in enumerate(results.items()):\n",
        "   ax = fig.add_subplot(gs[i // 2, i % 2])\n",
        "   ax.text(0.5, 0.9, pattern_name, ha='center', va='center', fontsize=14, fontweight='bold')\n",
        "\n",
        "   result_text = \"\\n\".join([f\"Response: {r[:100]}...\" if len(r) > 100 else f\"Response: {r}\" for r in pattern_results])\n",
        "   ax.text(0.5, 0.5, result_text, ha='center', va='center', fontsize=10, wrap=True)\n",
        "   ax.set_xlim(0, 1)\n",
        "   ax.set_ylim(0, 1)\n",
        "   ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print summary\n",
        "print(\"\\n=== LangGraph Agent Patterns Summary ===\")\n",
        "for pattern_name, pattern_results in results.items():\n",
        "   print(f\"\\n{pattern_name}:\")\n",
        "   for j, result in enumerate(pattern_results):\n",
        "       print(f\"  Response {j+1}: {result[:200]}...\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}